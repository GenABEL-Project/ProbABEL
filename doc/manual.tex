\title{ProbABEL manual}
\author{Yurii Aulchenko, Maksim Struchalin \\
	Erasmus MC Rotterdam
}
\date{\today}

\documentclass[12pt]{article}
\usepackage{verbatim}

\begin{document}
\maketitle
\tableofcontents

%\begin{abstract}
%This document describes ProbABEL package for analysis 
%of genome-wide imputed data \ldots
%\end{abstract}

\section{Motivation}

Many statistical and experimental techniques, such as imputations and 
high-throughput sequencing, generate the data, which are informative for 
genome-wide association analysis, and are probabilistic in the nature. 

When we work with directly genotyped markers using such techniques as 
SNP or microsatellite typing, we would normally know the genotype of 
a particular person at a particular locus with very high degree of 
confidence, and, in case of biallelic marker, can state whether 
genotype is $AA$, $AB$ or $BB$. 

On the contract, when dealing with imputed or 
high-throughput sequencing data, for many of genomic loci 
we are quite uncertainty about genotypic status of the person; 
instead of known genotypes  
we deal rather with probability distribution; that is based on 
observed information, we have estimates that true underlying 
genotype is either $AA$, $AB$ or $BB$; the degree of confidence 
about the real status is measured with 
probability distribution $\{P(AA), P(AB), P(BB)\}$.

Several techniques may be applied to analyse such data. The most 
simplistic approach would be to pick up the genotype with highest 
probability, i.e. $\max_g[P(g=AA), P(g=AB), P(g=BB)]$ and then 
analyse the data as if directly typed markers were used. The 
disadvantage of this approach is that it does not take into 
account the probability distribution -- i.e. the uncertainty 
about the true genotypic status. Such 
analysis is statistically wrong: the estimates of association 
parameters (regression coefficients, odds or hazard ratios, etc.) 
are biased, and the bias becomes more pronounced with greater 
probability distribution uncertainty (entropy). 

One of the solution which generates unbiased estimates 
of association parameters and takes 
probability distribution into account is achieved by 
performing association analysis by means of regression of the 
outcome of interest onto estimated genotypic probabilities. 

\texttt{ProbABEL} package was designed to perform such regression in fast, 
memory-efficient and consequently genome-wide feasible manner. 
Currently, \texttt{ProbABEL} implements linear, logistic regression, 
and Cox proportional hazards models. The corresponding analysis 
programs are called \texttt{palinear},  \texttt{palogist},  
and \texttt{pacoxph}.


\section{Input files}
\texttt{ProbABEL} takes three files as input: a file containing SNP 
information (e.g. MLINFO file of MACH), file with genome- or 
chromosome-wide predictor information (e.g. MLDOSE or MLPROB file of MACH), 
and a file containing phenotype of interest and covariates. 

Optionally, the map information can be supplied (e.g. "legend" 
files of HapMap). 

\subsection{SNP information file}
\label{ssec:infoin}
In the simplest scenario, SNP information file is an MLINFO 
file generated by MACH. This must be a space or tab-delimited file 
containing SNP name, coding for allele 1 and 2 (e.g. A, T, G or C), 
frequency of allele 1, minor allele frequency and two quality 
metrics ("Quality" = average maximum posterior probability and 
"Rsq" -- proportion of variance decrease after imputations). 

Actually, 
for \texttt{ProbABEL}, it does not matter what is written in this file -- 
this information is just brought forward to the output. However, 
\textbf{it is critical} that the number of columns is seven and the number 
of lines in the file is equal to the number of SNPs in the 
corresponding DOSE file (plus one for the header line). 

The example of SNP information file content follows here (also 
to be found in \texttt{ProbABEL/example/test.mlinfo})

\verbatiminput{../example/test.mlinfo}

Note that header line is present in the file. The file describes 
five SNPs. 

\subsection{Genomic predictor file}
\label{ssec:dosein}

Again under simplest scenario this is a MLDOSE or MLPROB file generated by MACH.
Such file starts with two special columns plus, for each of the SNPs 
under consideration, a column containing the estimated allele 1 dose (MLDOSE).
In MLPROB file, two columns for each SNP correspond to posterior probability 
that person has one or two copies of allele 1. 
The first ''special'' column is made of the sequential id, 
followed by an arrow followed by study ID (the one specified in 
MACH input files). The second column contains method 
(e.g. ''MLDOSE'') keyword.

An example of the few first lines of an MLDOSE file for 
five SNPs described in SNP information file follows here (also 
to be found in \texttt{ProbABEL/example/test.mldose})

\verbatiminput{short_test.mldose}

\textbf{The order of SNPs in the SNP information file and DOSE-file
must be the same}. This should be the case if you just used MACH outputs.

Thus, by all means, the number of columns in the genomic predictor file 
must be the same as the number of lines in the SNP information file plus one. 

\subsection{Phenotypic file}
\label{ssec:phenoin}

Phenotypic data file contains phenotypic data, but also specifies the 
analysis model. There is a header line, specifying the variable names. 
The first column should contain personal study IDs. It is assumed 
that \textbf{both the total number and the order of these IDs is are 
exactly the same as in the genomic predictor (MLDOSE) file described in 
previous section}. This is not difficult to arrange using e.g. \texttt{R}; 
example is given in \texttt{ProbABEL/examples} directory. 

\textbf{Missing data should be coded with 'NA', 'N' or 'NaN' codes.} Any 
other coding will be converted to some number which will be used in 
analysis! E.g. coding missing as '-999.9' will result in analysis which 
will consider -999.9 as indeed true measurements of the trait/covariates.  

In case of linear or logistic regression (programs \texttt{palinear} and 
\texttt{palogist}, respectively), the second column specifies the trait 
under analysis, while the third, fourth, etc. 
provide information on covariates to be included into analysis. 
An example few lines of phenotypic information file designed for 
linear regression analysis follow here (also 
to be found in \texttt{ProbABEL/example/height.txt})

\verbatiminput{short_height.txt}

Note again that the order of IDs is the same between MLDOSE and phenotypic 
data file. The model specified by this file is $height \sim \mu + sex + age$, 
where $\mu$ is intercept.  

Clearly, you can for example include \texttt{sex x age} interaction terms by 
specifying another column having a product of sex and age here.

For logistic regression, it is assumed that in the second column cases are 
coded as ''1'' and controls as ''0''. An example few lines of phenotypic 
information file designed for logistic regression analysis follow here (also 
to be found in \texttt{ProbABEL/example/logist\_data.txt})

\verbatiminput{short_logist_data.txt}

You can see that in the first 10 people, there are three cases, as indicated 
by ''chd'' equal to one. The model specified by this file 
is $chd \sim \mu + sex + age + othercov$.  

In case of Cox proportional hazards model, the composition of the 
phenotypic input file is a bit different. In the second column and 
third column, you need to specify the outcome in terms of follow-up 
time (column two) and event (column three, ''1'' if event occurred 
and zero if censoring). Columns from four inclusive specify covariates 
to be included into analysis. An example few lines of phenotypic 
information file designed for Cox proportional hazards model 
analysis follow here \\(also to be found in
\texttt{ProbABEL/example/coxph\_data.txt})

\verbatiminput{short_coxph_data.txt}

You can see that for first 10 people, event happens for three of 
them, while for the other seven there is no event during follow-up 
time, as indicated 
by ''chd'' column. Follow-up time is specified in the preceding 
column. The covariates included into the model are age (presumably 
at baseline), sex and ''othercov''; thus the model, in terms of 
\texttt{R/survival} is \\ $Surv(fuptime\_chd, chd) \sim sex + age + othercov$.  

\subsection{Optional map file}
If you would like that map information (e.g. base pair position) to 
be included in your outputs, you can supply a map file. These follow 
HapMap "legend" file format. For example, for the five SNPs we considered 
the map-file may look like

\verbatiminput{../example/test.map}

The order of the SNPs in the map file should follow that in the SNP information 
file. Only information from the second column -- the SNP location -- is 
actually used to generate the output.

\section{Running analysis}

To run linear regression, you should use program called \texttt{palinear};
for logistic analysis use \texttt{palogist}, and for Cox proportional 
hazards model use \texttt{pacoxph} (to be found in 
\texttt{ProbABEL/bin/} directory after you have compiled the program).

There are in total 11 command line options you can specify to \texttt{ProbABEL} 
analysis functions \texttt{linear} or \texttt{logistic}. If you run 
either program without any argument, you 
will get a short explanation to command line options:

\begin{verbatim}
user@server~$ palogist

Usage: ../bin/palogist options

Options:
		--pheno       : phenotype file name
		--info        : information (e.g. MLINFO) file name
		--dose        : predictor (e.g. MLDOSE/MLPROB) file name
		--map         : [optional] map file name
		--nids        : [optional] number of people to analyse
		--chrom       : [optional] chromosome (to be passed to output)
		--out         : [optional] output file name (default is regression.out.txt)
		--skipd       : [optional] how many columns to skip in predictor
								    (dose/prob) file (default 2)
		--ntraits     : [optional] how many traits are analysed (default 1)
		--ngpreds     : [optional] how many predictor columns per marker
								    (default 1 = MLDOSE; else use 2 for MLPROB)
		--separat     : [optional] character to separate fields (default is space)
		--score       : use score test
		--no-head     : do not report header line
		--allcov      : report estimates for all covariates (large outputs!)
		--interaction : which covariate to use for interaction with SNP
									  (default is no ineraction, 0)
		--interaction_only: like previos but without covariate acting in
                    interaction with SNP
									  (default is no ineraction, 0)
		--mmscore     : score test for association between a trait and genetic
                    polymorphism, in samples of related individuals	
		--help        : print help

\end{verbatim}


%\subsection{Basic analysis options}
However, for 
a simple run you can use only three, which specify the necessary files 
needed to run regression analysis.

These options are 
\texttt{--dose} (or \texttt{-d}), 
specifying genomic predictor / MLDOSE file described in sub-section \ref{ssec:dosein};
\texttt{--pheno} (or \texttt{-p}), 
specifying the phenotypic data file described in sub-section \ref{ssec:phenoin}; and
\texttt{--info} (or \texttt{-i}), 
specifying the SNP information file described in sub-section \ref{ssec:infoin}.

If you change to the \texttt{ProbABEL/example} directory you can run analysis of 
height by 

\begin{verbatim}
user@server~/ProbABEL/example/$ ../bin/palinear -p height.txt 
-d test.mldose -i test.mlinfo
\end{verbatim}

Output from analysis will be directed to "regression.out.csv" file.

You can run analysis of binary trait "chd" with 

\begin{verbatim}
user@server~/ProbABEL/example/$ ../bin/palogist -p logist_data.txt 
                                 -d test.mldose -i test.mlinfo
\end{verbatim}

To run a Cox proportional hazards model, try 

\begin{verbatim}
user@server~/ProbABEL/example/$ ../bin/pacoxph -p coxph_data.txt 
                                 -d test.mldose -i test.mlinfo
\end{verbatim}

Please have a look at the shell script files \texttt{example\_qt.sh}, 
\texttt{example\_bt.sh} and \texttt{example\_all.sh} to have 
a better overview of analysis options.

To run analysis with MLPROB files, you need specify the MLPROB file 
with -d option and also specify that there are two genetic predictors 
per SNP, e.g. you can run linear model with

\begin{verbatim}
user@server~/ProbABEL/example/$ ../bin/palinear -p height.txt 
                                 -d test.mlprob -i test.mlinfo --ngpreds=2
\end{verbatim}

Option \texttt{--interaction} allows you to include interaction between SNP 
and any covariate. If e.g. your model is \texttt{trait ~ sex + age + SNP}, 
running the program with option \texttt{--interaction=2} will model 
\texttt{trait ~ sex + age + SNP + age*SNP}.

Option \texttt{--interaction\_only} is like \texttt{--interaction} but does not include covariate acting in interaction with SNP.
If you have one covariate in input phenotype file for example and would like to exclude this covariate from model itself (hold only interaction term) than use
option \texttt{--interaction\_only1}.

Perl script \texttt{bin/probabel.pl\_example} represents a handy wraper for ProbABEL functions. 
To start using it you have to change config file \\
\texttt{bin/probabel\_config.cfg\_example}.
Configuration file consists of 5 columns. Each column except of the first is pattern for 
files produced by \texttt{MACH} (imputation software). 
Column named "cohort" is name of population ("ERGO" in this example), column "mlinfo\_path" -- 
full path to mlinfo files and pattern of name where chromosome number has been 
replaced by "\_.\_chr\_.\_". Columns "mldose\_path", "mlprobe\_path" and "legend\_path" 
are paths and patterns for "mldose", "mlprob" and "legend" files.
Probably you also have to change variable \texttt{\$config} in sript to point full path to 
configuration file and variable \texttt{@anprog } to point full path to ProbABEL scripts.


With option \texttt{--mmscore} score test for association between a trait and genetic
polymorphism  in samples of related individuals is performed. File with inverse of variance-covarince matrix goes as input parameter
with that key. Like \texttt{--mmscore <filename>}. The file has to contain the first column with id names exactly like in phenotype file, BUT OMITTING people with no measured phenotype. The rest is a matrix.
Phenotype file in case of using key --mscore may contain any amount of covariates (opposed to previous versions). The first is id names, the second - trait. 
Otheres are covariates.

An example how polygenic object estimated by GenABEL can be used with ProbABEL is provided here: example/mmscore.R


%\subsection{Extended analysis options}

\section{Output file format}

Let us consider what comes out of the linear regression analysis 
described in the above section. After you have run the analysis, in 
the output file you will find something like

\begin{small}
\verbatiminput{short_height.out.csv}
\end{small}

Here, I show only three first lines of output. Note that lines 
starting with ''...'' are actually the ones continuing the 
previous line -- I just have wrapped this output so we can see 
these long lines. 

The header provides short description of what can be found in the 
specific column. The first column provides the SNP name and 
next six are descriptives which were brought directly from the 
SNP information file. Thus these describe allele frequencies and 
quality in your total imputations, not necessarily in the data under 
analysis. 

On the contrast, starting with the next column, named ''n'', 
the output concerns the data analysed. Column 8 (''n'') tells the 
number of subjects for whom complete phenotypic information was available. 
At this point, unless you have complete measurements on all 
subjects, you should feel warned if the number here is exactly the 
number of people in the file -- this probably indicates you did not code 
missing values according to \texttt{ProbABEL} format ('NA', 'NaN', or 'N').

The next column nine (''Mean\_predictor\_allele'') gives you estimated 
frequency of the predictor allele in subjects with complete phenotypic data. 

If ''--chrom'' option was used, in the next column you will find the 
value specified by this option. If ''--map'' option was used, in next 
column you will find map location brought from the map-file. Next 
columns provide coefficients of regression  of the phenotype 
onto genotype, corresponding standard errors, and the $\chi^2$ 
of the Likelihood Ratio Test for deviation from zero.

\section{Preparing input files}

In the \texttt{ProbABEL/bin} directory you can find \texttt{perepare\_data.R}
file -- an R script which arranges phenotypic data in right format. 
Please read this script for details.

\section{Memory use and performance}

Maximum likelihood regression is implemented in \texttt{ProbABEL}. With 6,000 
people and 2.5 millions SNPs, genome-wide scan is completed in less 
that an hour for linear model with 1-2 covariates and overnight 
for logistic regression or Cox proportional hazards model.

Memory is an issue with \texttt{ProbABEL} -- large chromosomes, 
such as chromosme one consumed up to 5Gb RAM with 6,000 people. 

\section{Methodology}

\subsection{Linear regression}

Standard linear theory is used to estimate betas and their standard 
errors. We assume linear model with expectation
\begin{equation}
E[\mathbf{Y}] = \mathbf{X} \mathbf{\beta}
\end{equation}
and variance-covaraince matrix 
$$
\mathbf{V} = \sigma^2 \mathbf{I}
$$
where $\mathbf{Y}$ is the vector of phenotypes of interest, 
$\mathbf{X}$ is design matrix, $\mathbf{\beta}$ is the vector of regression 
parameters, $\sigma^2$ is variance and $\mathbf{I}$ is identity matrix. 

The maximum likelihood estimates (MLEs) for the regression parameters 
is given by
\begin{equation}
\hat{\beta} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}
\end{equation}
and MLE of the variance is
\begin{equation}
\hat{\sigma}^2 = \frac{(\mathbf{Y} - \mathbf{X}\hat{\beta})^T (\mathbf{Y} - \mathbf{X}\hat{\beta})}
			{N-r_X}
\end{equation}
where $N$ is the number of observations and $r_X$ is rank of $\mathbf{X}$ 
(number of columns of the design matrix). 

Standard errors for the $j$-{th} parameter can be obtained as 
\begin{equation}
s.e.(\hat{\beta}_j) = \hat{\sigma}^2 (\mathbf{X}^T\mathbf{X})^{-1}_{jj}
\end{equation}
where $(\mathbf{X}^T\mathbf{X})^{-1}_{jj}$ stands for the $j$-th diagonal 
element of the inverse of matrix $(\mathbf{X}^T\mathbf{X})$.

\subsection{Logistic regression}

Standard methodology based on iteratively re-weighted least squares is 
used to obtain parameters' estimates. 

\subsection{Cox proportional hazards model}

The code of this section is entirely based on the code of \texttt{R} 
library \texttt{survival} code developed by Thomas Lumley 
(function \texttt{coxfit2}). 

Many thanks to Thomas for making his code available under GNU GPL!

\section{How to cite}

As for May 2008, we have not yet published 
\texttt{ProbABEL} paper. If you used \texttt{ProbABEL} for 
your analysis please give a link to the \texttt{ABEL} home 
page 

\begin{quote}
http://mga.bionet.nsc.ru/~yurii/ABEL/
\end{quote}

and cite \texttt{GenABEL} paper to give us some credit: 

\begin{quote}
Aulchenko YS, Ripke S, Isaacs A, van Duijn CM.
GenABEL: an R library for genome-wide association analysis.
Bioinformatics. 2007 23(10):1294-6. 
\end{quote}

Proper reference may look like 

\begin{quote}
For analysis of imputed data, we used \texttt{ProbABEL} package 
from the ABEL 
set of programs (Aulchenko et al., 2007). 
\end{quote}

If you have used Cox proportional hazard model, please mention 
\texttt{R} package \texttt{survival} by Thomas Lumley. Additionally 
to the above citation, please tell that 

\begin{quote}
Cox proportional hazards model implemented in \texttt{ProbABEL} 
makes use of the source code of \texttt{R} package ''\texttt{survival}'' 
as implemented by T. Lumley. 
\end{quote}


%\subsection{Generalized linear models}

%Let us define linear predictor $\eta$ as 
%$$
%\eta = \mathbf{X} \beta
%$$
%For regular linear regression model described in previous section 
%this linear predictor models the expectation of the trait of interest, 
%while 

%\begin{table}
%\begin{center}
%\caption{Link .. functions}
%\begin{tabular}{lccc}
%\hline
%Distribution & $\mu$ & $\tau^2$ & $v(\mu)$ \\
%\hline
%Normal	 &            $\eta$ & $\sigma^2$ & \\
%Binomial & $1/(1+e^{-\eta})$ & & \\
%Poisson  &        $e^{\eta}$ & & \\
%\hline
%\end{tabular}
%\end{center}
%\end{table}

%Iteratively re-weighted least squares are used to obtain parameters' 
%estimates. 

\end{document}
